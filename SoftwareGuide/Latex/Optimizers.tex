
\index{itk::Optimizer|textbf}
\index{itk::SingleValuedNonLinearOptimizer|textbf}

Optimization algorithms are encapsulated as \code{itk::Optimizer} objects
within ITK. Optimizers are generic and can be used for general applications.
Within the registration framework, \code{itk::SingleValuedNonLinearOptimizer}
are used to optimize the metric criterion with respect to transform parameters.

\index{itk::Optimizer!SetInitialPosition()}
\index{itk::Optimizer!StartOptimization()}
\index{itk::Optimizer!GetCurrentPosition()}

The basic input to an optimizer is a cost function object. In context
of registration, \code{itk::ImageToImageMetrics} provide this functionality.
The initial parameters are set using \code{SetInitialPosition()} and
the optimization algorithm is invoked by \code{StartOptimization()}.
Once the optimization has finished, the final parameters can be obtained
using \code{GetCurrentPosition()}.

\index{itk::Optimizer!SetScales()}
Some optimizers also allows rescaling of the individual parameters. This
is convenient for normalizing parameters spaces in which some parameters
have different dynamic range. For example, the first parameter of
\code{Euler2DTransform} represent an angle while the last two parameters
the translation. A unit change in angle has a much greater impact on
an image than a unit change in translation. This difference in scale appears
as long narrow valleys in the search space making the optimization problem
diffcult. Scales are represented as \code{Array} of doubles and set via
\code{SetScales()}.

The types of \code{itk::SingleValuedNonLinearOptimizer} currently available
in ITK are:

\begin{itemize}

\item \textbf{Amoeba}: Nelder-Meade downhill simplex.

\item \textbf{Conjugate Gradient}: Fletcher-Reeves form 
of conjugate gradient with or without preconditioning.

\item \textbf{Gradient Descent}: Advance parameters in the direction of the
gradient where the step size is governed by a learning rate. 

\item \textbf{Quaterion Rigid Transform Gradient Descent}: 
A specialized version of \code{GradientDescentOptimizer} for
\code{QuaternionRigidTransform} parameters, where the parameters
representing the quaternion is normalize to a magnitude to one at each
iteration to represent a pure rotation.

\item \textbf{LBFGS}: Limited memory Broyden, Fletcher, Goldfarb
and Shannon minmization.

\item \textbf{Levenberg Marquardt}: Non-linear least squares minimization.

\item \textbf{One Plus One Evolutionary}: Strategy that simulates the 
biological evoluation of a set of samples in the search space.

\item \textbf{Regular Step Gradient Descent}: Advance parameters in the
direction of the gradient where a bipartition scheme is used to compute
the step size. 

\item \textbf{Versor Transform Optimzier}:
A specialized version of \code{RegularStepGradientDescentOptimizer}
for \code{VersorRigid3DTransform} parameters.
where the current rotation is composed with the gradient rotation
to produce the new rotation vector.

\end{itemize}



